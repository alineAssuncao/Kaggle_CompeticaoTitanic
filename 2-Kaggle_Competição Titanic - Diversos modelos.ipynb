{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competição de Machine Learning Kaggle Titanic\n",
    "by Aline Assunção\n",
    "\n",
    "Site utilizados para a construção da solução: https://www.kaggle.com/c/titanic,  http://mundoia.com.br/tutorial/conheca-o-kaggle-e-participe-da-sua-primeira-competicao-de-machine-learning/ e https://guidefreitas.github.io/ia/machinelearning/2017/04/10/Kaggle-Titanic.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrição da Competição\n",
    "\n",
    "O naufrágio do RMS Titanic é um dos mais infames naufrágios da história. Em 15 de abril de 1912, durante sua viagem inaugural, o Titanic afundou depois de colidir com um iceberg, matando 1502 de 2224 passageiros e tripulantes. Essa tragédia sensacional chocou a comunidade internacional e levou a melhores normas de segurança para os navios.\n",
    "\n",
    "Uma das razões pelas quais o naufrágio causou tamanha perda de vidas foi que não havia botes salva-vidas suficientes para os passageiros e a tripulação. Embora houvesse algum elemento de sorte envolvido na sobrevivência do naufrágio, alguns grupos de pessoas tinham maior probabilidade de sobreviver do que outros, como mulheres, crianças e a classe alta.\n",
    "\n",
    "Neste desafio, é solicitado que concluamos a análise de quais tipos de pessoas provavelmente sobreviveriam. Aplicando as ferramentas de aprendizado de máquina para prever quais passageiros sobreviveram à tragédia.\n",
    "\n",
    "Praticar Habilidades\n",
    "- Classificação binária\n",
    "- Noções básicas de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "\n",
    "O trabalho é prever se um passageiro sobreviveu ao naufrágio do Titanic ou não.\n",
    "Para cada PassengerId no conjunto de testes, deve-se prever um valor 0 ou 1 para a variável Survived.\n",
    "\n",
    "\n",
    "### Métrica\n",
    "\n",
    "A pontuação é a porcentagem de passageiros que você prevê corretamente. Isso é conhecido simplesmente como \"acurácia\".\n",
    "\n",
    "\n",
    "### Formato de Arquivo de Submissão\n",
    "\n",
    "Enviar um arquivo csv com exatamente 418 entradas mais uma linha de cabeçalho. O envio mostrará um erro se tiver colunas extras (além de PassengerId e Survived) ou linhas.\n",
    "\n",
    "O arquivo deve ter exatamente 2 colunas:\n",
    "- PassengerId (classificado em qualquer ordem)\n",
    "- Survived (contém suas previsões binárias: 1 para sobreviventes, 0 para mortos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descrição dos Dados\n",
    "\n",
    "Temos dois datasets uma para treinar o modelo e outro para o envio do arquivo que o Kaggle espera.\n",
    "- training set (train.csv)\n",
    "- test set (test.csv)\n",
    "\n",
    "### Dicionário dos dados\n",
    "\n",
    "PassengerId: Número de identificação do passageiro;\n",
    "\n",
    "Survived: Indica se o passageiro sobreviveu ao desastre. É atribuído o valor de 0 para aqueles que não sobreviveram, e 1 para quem sobreviveu;\n",
    "\n",
    "Pclass: Classe na qual o passageiro viajou. É informado 1 para primeira classe; 2 para segunda; e 3 para terceira;\n",
    "\n",
    "Name: Nome do passageiro;\n",
    "\n",
    "Sex: Sexo do passageiro;\n",
    "\n",
    "Age: Idade do passageiro em anos;\n",
    "\n",
    "SibSp: Quantidade de irmãos e cônjuges a bordo ;\n",
    "\n",
    "Parch: Quantidade de pais e filhos a bordo;\n",
    "\n",
    "Ticket: Número da passagem;\n",
    "\n",
    "Fare: Preço da passagem;\n",
    "\n",
    "Cabin: Número da cabine do passageiro;\n",
    "\n",
    "Embarked: Indica o porto no qual o passageiro embarcou. Há apenas três valores possíveis: Cherbourg, Queenstown e Southampton, indicados pelas letras “C”, “Q” e “S”, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro importamos as bibliotecas que precisamos. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lendo os conjuntos de teste e treino - read_csv do Pandas\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "full = train.append( test , ignore_index = True )\n",
    "titanic = full[ :891 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.Series( np.where( full.Sex == 'male' , 1 , 0 ) , name = 'Sex' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked = pd.get_dummies( full.Embarked , prefix='Embarked' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass = pd.get_dummies( full.Pclass , prefix='Pclass' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = pd.DataFrame()\n",
    "imputed[ 'Age' ] = full.Age.fillna( full.Age.mean() )\n",
    "imputed[ 'Fare' ] = full.Fare.fillna( full.Fare.mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cabin = pd.DataFrame()\n",
    "\n",
    "#Substitui os dados de cabines faltantes com U (Unknown)\n",
    "cabin[ 'Cabin' ] = full.Cabin.fillna( 'U' )\n",
    "\n",
    "# mapping each Cabin value with the cabin letter\n",
    "cabin[ 'Cabin' ] = cabin[ 'Cabin' ].map( lambda c : c[0] )\n",
    "cabin = pd.get_dummies( cabin['Cabin'] , prefix = 'Cabin' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_T</th>\n",
       "      <th>Cabin_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>38.500000</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>29.881138</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age      Fare  Embarked_C  Embarked_Q  Embarked_S  Pclass_1  \\\n",
       "1304  29.881138    8.0500           0           0           1         0   \n",
       "1305  39.000000  108.9000           1           0           0         1   \n",
       "1306  38.500000    7.2500           0           0           1         0   \n",
       "1307  29.881138    8.0500           0           0           1         0   \n",
       "1308  29.881138   22.3583           1           0           0         0   \n",
       "\n",
       "      Pclass_2  Pclass_3  Sex  Cabin_A  Cabin_B  Cabin_C  Cabin_D  Cabin_E  \\\n",
       "1304         0         1    1        0        0        0        0        0   \n",
       "1305         0         0    0        0        0        1        0        0   \n",
       "1306         0         1    1        0        0        0        0        0   \n",
       "1307         0         1    1        0        0        0        0        0   \n",
       "1308         0         1    1        0        0        0        0        0   \n",
       "\n",
       "      Cabin_F  Cabin_G  Cabin_T  Cabin_U  \n",
       "1304        0        0        0        1  \n",
       "1305        0        0        0        0  \n",
       "1306        0        0        0        1  \n",
       "1307        0        0        0        1  \n",
       "1308        0        0        0        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_X = pd.concat( [ imputed , embarked , pclass , sex, cabin ] , axis=1 )\n",
    "full_X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_X_norm = full_X.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "full_X['Age'] = full_X_norm['Age']\n",
    "full_X['Fare'] = full_X_norm['Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_X = full_X[ 0:891 ]\n",
    "train_valid_y = titanic.Survived\n",
    "test_X = full_X[ 891: ]\n",
    "train_X , valid_X , train_y , valid_y = train_test_split( train_valid_X , train_valid_y , train_size = 0.7 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (Support Vector Machine)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8206420867820416 0.8493324649951156\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.754 (+/-0.050) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.306 (+/-0.002) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.306 (+/-0.002) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.306 (+/-0.002) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.022) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.750 (+/-0.034) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.306 (+/-0.002) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.306 (+/-0.002) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.741 (+/-0.053) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.022) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.749 (+/-0.031) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.306 (+/-0.002) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.791 (+/-0.042) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.739 (+/-0.051) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.022) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.750 (+/-0.034) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.739 (+/-0.051) for {'C': 1, 'kernel': 'linear'}\n",
      "0.739 (+/-0.051) for {'C': 10, 'kernel': 'linear'}\n",
      "0.739 (+/-0.051) for {'C': 100, 'kernel': 'linear'}\n",
      "0.739 (+/-0.051) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.93      0.88       168\n",
      "         1.0       0.86      0.71      0.78       100\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       268\n",
      "   macro avg       0.85      0.82      0.83       268\n",
      "weighted avg       0.85      0.85      0.84       268\n",
      "\n",
      "\n",
      "0.7773041799527125 0.8192857142857143\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.740 (+/-0.037) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.737 (+/-0.031) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.740 (+/-0.033) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.738 (+/-0.055) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.737 (+/-0.031) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.739 (+/-0.029) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.750 (+/-0.056) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.736 (+/-0.055) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.737 (+/-0.031) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.740 (+/-0.033) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.736 (+/-0.055) for {'C': 1, 'kernel': 'linear'}\n",
      "0.736 (+/-0.055) for {'C': 10, 'kernel': 'linear'}\n",
      "0.736 (+/-0.055) for {'C': 100, 'kernel': 'linear'}\n",
      "0.736 (+/-0.055) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.93      0.88       168\n",
      "         1.0       0.86      0.71      0.78       100\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       268\n",
      "   macro avg       0.85      0.82      0.83       268\n",
      "weighted avg       0.85      0.85      0.84       268\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    model = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,\n",
    "                           scoring='%s_macro' % score)\n",
    "    model.fit(train_X , train_y)\n",
    "\n",
    "    # Score the model\n",
    "    print (model.score( train_X , train_y ) , model.score( valid_X , valid_y ))\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(model.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = model.cv_results_['mean_test_score']\n",
    "    stds = model.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = valid_y, model.predict(valid_X)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_X = test_X.as_matrix()\n",
    "\n",
    "test_Y = model.predict( t_X )\n",
    "test_Y = test_Y.flatten().round().astype(int)\n",
    "passenger_id = full[891:].PassengerId\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y } )\n",
    "test.shape\n",
    "test.head()\n",
    "test.to_csv( 'result/submission_SVM.csv' , index = False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perception - MLP (Scikit Learn)\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.7784911717495987\n",
      "Test: 0.8171641791044776\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(6, 2), random_state=1)\n",
    "model.fit( train_X , train_y )\n",
    "\n",
    "# Score the model\n",
    "print (\"Train: \", model.score( train_X , train_y ))\n",
    "print (\"Test:\", model.score( valid_X , valid_y ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_X = test_X.as_matrix()\n",
    "\n",
    "test_Y = model.predict( t_X )\n",
    "test_Y = test_Y.flatten().round().astype(int)\n",
    "passenger_id = full[891:].PassengerId\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y } )\n",
    "test.shape\n",
    "test.head()\n",
    "test.to_csv( 'result/submission_MLP.csv' , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.985553772070626\n",
      "Test: 0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(train_X , train_y)\n",
    "print (\"Train: \", model.score( train_X , train_y ))\n",
    "print (\"Test:\", model.score( valid_X , valid_y ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8202247191011236\n",
      "Test: 0.8694029850746269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(n_estimators=50)\n",
    "model.fit(train_X , train_y)\n",
    "print (\"Train: \", model.score( train_X , train_y ))\n",
    "print (\"Test:\", model.score( valid_X , valid_y ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.8426966292134831\n",
      "Test: 0.8619402985074627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "model.fit(train_X , train_y)\n",
    "print (\"Train: \", model.score( train_X , train_y ))\n",
    "print (\"Test:\", model.score( valid_X , valid_y ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_X = test_X.as_matrix()\n",
    "\n",
    "test_Y = model.predict( t_X )\n",
    "test_Y = test_Y.flatten().round().astype(int)\n",
    "passenger_id = full[891:].PassengerId\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y } )\n",
    "test.shape\n",
    "test.head()\n",
    "test.to_csv( 'result/submission_DT3.csv' , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\aline\\anaconda3\\lib\\site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\aline\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\aline\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\aline\\anaconda3\\lib\\site-packages (from keras) (2.8.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\aline\\anaconda3\\lib\\site-packages (from keras) (1.15.4)\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.7 keras-preprocessing-1.0.9\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.78587290e-02 -4.97068668e-02  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 2.14441467e-01 -5.13253574e-02  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 4.02340753e-01 -4.60797067e-02  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 1.07965205e-01 -5.08373899e-02  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 3.56027927e-16 -4.92758939e-02  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 3.56027927e-16 -2.13479522e-02  1.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "t_X = train_X.as_matrix()\n",
    "t_y = train_y.as_matrix()\n",
    "#t_y = to_categorical(t_y)\n",
    "\n",
    "v_X = valid_X.as_matrix()\n",
    "v_y = valid_y.as_matrix()\n",
    "#v_y = to_categorical(v_y)\n",
    "\n",
    "test_X_m = test_X.as_matrix()\n",
    "print(test_X_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_X = test_X.as_matrix()\n",
    "\n",
    "test_Y = model.predict( t_X )\n",
    "test_Y = test_Y.flatten().round().astype(int)\n",
    "passenger_id = full[891:].PassengerId\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y } )\n",
    "test.shape\n",
    "test.head()\n",
    "test.to_csv( 'result/submission_GNB.csv' , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
